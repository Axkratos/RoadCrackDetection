{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bTa9-9cPhw28"
   },
   "source": [
    "Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "df59349a91be49958f0e9c952eab70e5",
      "58f1887301894637a3ac898a12e3c8bd",
      "c8303ba8d6724474b954ff977d7fd20d",
      "83e2a80ebc624b76a138fa715a3bc60a",
      "dfbebb0075d64540963015a7f02f4645",
      "508be4b681de4f919edca4f319439a0e",
      "408ba5c24fe84cba91ebb5dd2646e209",
      "9fd4845738054238b62e6f264e9b2f44"
     ]
    },
    "id": "YTX1fX_cWPgL",
    "outputId": "5f8dc962-5946-44b8-8b9e-28f96119dbcf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The class labels are: ['D00', 'D01', 'D10', 'D11', 'D20', 'D40', 'D43', 'D44'] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anupa\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\anupa\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet161_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet161_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2208\n",
      "Epoch: 1\n",
      "Batch: 1 out of 296\n",
      "Batch: 2 out of 296\n",
      "Batch: 3 out of 296\n",
      "Batch: 4 out of 296\n",
      "Batch: 5 out of 296\n",
      "Batch: 6 out of 296\n",
      "Batch: 7 out of 296\n",
      "Batch: 8 out of 296\n",
      "Batch: 9 out of 296\n",
      "Batch: 10 out of 296\n",
      "Batch: 11 out of 296\n",
      "Batch: 12 out of 296\n",
      "Batch: 13 out of 296\n",
      "Batch: 14 out of 296\n",
      "Batch: 15 out of 296\n",
      "Batch: 16 out of 296\n",
      "Batch: 17 out of 296\n",
      "Batch: 18 out of 296\n",
      "Batch: 19 out of 296\n",
      "Batch: 20 out of 296\n",
      "Batch: 21 out of 296\n",
      "Batch: 22 out of 296\n",
      "Batch: 23 out of 296\n",
      "Batch: 24 out of 296\n",
      "Batch: 25 out of 296\n",
      "Batch: 26 out of 296\n",
      "Batch: 27 out of 296\n",
      "Batch: 28 out of 296\n",
      "Batch: 29 out of 296\n",
      "Batch: 30 out of 296\n",
      "Batch: 31 out of 296\n",
      "Batch: 32 out of 296\n",
      "Batch: 33 out of 296\n",
      "Batch: 34 out of 296\n",
      "Batch: 35 out of 296\n",
      "Batch: 36 out of 296\n",
      "Batch: 37 out of 296\n",
      "Batch: 38 out of 296\n",
      "Batch: 39 out of 296\n",
      "Batch: 40 out of 296\n",
      "Batch: 41 out of 296\n",
      "Batch: 42 out of 296\n",
      "Batch: 43 out of 296\n",
      "Batch: 44 out of 296\n",
      "Batch: 45 out of 296\n",
      "Batch: 46 out of 296\n",
      "Batch: 47 out of 296\n",
      "Batch: 48 out of 296\n",
      "Batch: 49 out of 296\n",
      "Batch: 50 out of 296\n",
      "Batch: 51 out of 296\n",
      "Batch: 52 out of 296\n",
      "Batch: 53 out of 296\n",
      "Batch: 54 out of 296\n",
      "Batch: 55 out of 296\n",
      "Batch: 56 out of 296\n",
      "Batch: 57 out of 296\n",
      "Batch: 58 out of 296\n",
      "Batch: 59 out of 296\n",
      "Batch: 60 out of 296\n",
      "Batch: 61 out of 296\n",
      "Batch: 62 out of 296\n",
      "Batch: 63 out of 296\n",
      "Batch: 64 out of 296\n",
      "Batch: 65 out of 296\n",
      "Batch: 66 out of 296\n",
      "Batch: 67 out of 296\n",
      "Batch: 68 out of 296\n",
      "Batch: 69 out of 296\n",
      "Batch: 70 out of 296\n",
      "Batch: 71 out of 296\n",
      "Batch: 72 out of 296\n",
      "Batch: 73 out of 296\n",
      "Batch: 74 out of 296\n",
      "Batch: 75 out of 296\n",
      "Batch: 76 out of 296\n",
      "Batch: 77 out of 296\n",
      "Batch: 78 out of 296\n",
      "Batch: 79 out of 296\n",
      "Batch: 80 out of 296\n",
      "Batch: 81 out of 296\n",
      "Batch: 82 out of 296\n",
      "Batch: 83 out of 296\n",
      "Batch: 84 out of 296\n",
      "Batch: 85 out of 296\n",
      "Batch: 86 out of 296\n",
      "Batch: 87 out of 296\n",
      "Batch: 88 out of 296\n",
      "Batch: 89 out of 296\n",
      "Batch: 90 out of 296\n",
      "Batch: 91 out of 296\n",
      "Batch: 92 out of 296\n",
      "Batch: 93 out of 296\n",
      "Batch: 94 out of 296\n",
      "Batch: 95 out of 296\n",
      "Batch: 96 out of 296\n",
      "Batch: 97 out of 296\n",
      "Batch: 98 out of 296\n",
      "Batch: 99 out of 296\n",
      "Batch: 100 out of 296\n",
      "Batch: 101 out of 296\n",
      "Batch: 102 out of 296\n",
      "Batch: 103 out of 296\n",
      "Batch: 104 out of 296\n",
      "Batch: 105 out of 296\n",
      "Batch: 106 out of 296\n",
      "Batch: 107 out of 296\n",
      "Batch: 108 out of 296\n",
      "Batch: 109 out of 296\n",
      "Batch: 110 out of 296\n",
      "Batch: 111 out of 296\n",
      "Batch: 112 out of 296\n",
      "Batch: 113 out of 296\n",
      "Batch: 114 out of 296\n",
      "Batch: 115 out of 296\n",
      "Batch: 116 out of 296\n",
      "Batch: 117 out of 296\n",
      "Batch: 118 out of 296\n",
      "Batch: 119 out of 296\n",
      "Batch: 120 out of 296\n",
      "Batch: 121 out of 296\n",
      "Batch: 122 out of 296\n",
      "Batch: 123 out of 296\n",
      "Batch: 124 out of 296\n",
      "Batch: 125 out of 296\n",
      "Batch: 126 out of 296\n",
      "Batch: 127 out of 296\n",
      "Batch: 128 out of 296\n",
      "Batch: 129 out of 296\n",
      "Batch: 130 out of 296\n",
      "Batch: 131 out of 296\n",
      "Batch: 132 out of 296\n",
      "Batch: 133 out of 296\n",
      "Batch: 134 out of 296\n",
      "Batch: 135 out of 296\n",
      "Batch: 136 out of 296\n",
      "Batch: 137 out of 296\n",
      "Batch: 138 out of 296\n",
      "Batch: 139 out of 296\n",
      "Batch: 140 out of 296\n",
      "Batch: 141 out of 296\n",
      "Batch: 142 out of 296\n",
      "Batch: 143 out of 296\n",
      "Batch: 144 out of 296\n",
      "Batch: 145 out of 296\n",
      "Batch: 146 out of 296\n",
      "Batch: 147 out of 296\n",
      "Batch: 148 out of 296\n",
      "Batch: 149 out of 296\n",
      "Batch: 150 out of 296\n",
      "Batch: 151 out of 296\n",
      "Batch: 152 out of 296\n",
      "Batch: 153 out of 296\n",
      "Batch: 154 out of 296\n",
      "Batch: 155 out of 296\n",
      "Batch: 156 out of 296\n",
      "Batch: 157 out of 296\n",
      "Batch: 158 out of 296\n",
      "Batch: 159 out of 296\n",
      "Batch: 160 out of 296\n",
      "Batch: 161 out of 296\n",
      "Batch: 162 out of 296\n",
      "Batch: 163 out of 296\n",
      "Batch: 164 out of 296\n",
      "Batch: 165 out of 296\n",
      "Batch: 166 out of 296\n",
      "Batch: 167 out of 296\n",
      "Batch: 168 out of 296\n",
      "Batch: 169 out of 296\n",
      "Batch: 170 out of 296\n",
      "Batch: 171 out of 296\n",
      "Batch: 172 out of 296\n",
      "Batch: 173 out of 296\n",
      "Batch: 174 out of 296\n",
      "Batch: 175 out of 296\n",
      "Batch: 176 out of 296\n",
      "Batch: 177 out of 296\n",
      "Batch: 178 out of 296\n",
      "Batch: 179 out of 296\n",
      "Batch: 180 out of 296\n",
      "Batch: 181 out of 296\n",
      "Batch: 182 out of 296\n",
      "Batch: 183 out of 296\n",
      "Batch: 184 out of 296\n",
      "Batch: 185 out of 296\n",
      "Batch: 186 out of 296\n",
      "Batch: 187 out of 296\n",
      "Batch: 188 out of 296\n",
      "Batch: 189 out of 296\n",
      "Batch: 190 out of 296\n",
      "Batch: 191 out of 296\n",
      "Batch: 192 out of 296\n",
      "Batch: 193 out of 296\n",
      "Batch: 194 out of 296\n",
      "Batch: 195 out of 296\n",
      "Batch: 196 out of 296\n",
      "Batch: 197 out of 296\n",
      "Batch: 198 out of 296\n",
      "Batch: 199 out of 296\n",
      "Batch: 200 out of 296\n",
      "Batch: 201 out of 296\n",
      "Batch: 202 out of 296\n",
      "Batch: 203 out of 296\n",
      "Batch: 204 out of 296\n",
      "Batch: 205 out of 296\n",
      "Batch: 206 out of 296\n",
      "Batch: 207 out of 296\n",
      "Batch: 208 out of 296\n",
      "Batch: 209 out of 296\n",
      "Batch: 210 out of 296\n",
      "Batch: 211 out of 296\n",
      "Batch: 212 out of 296\n",
      "Batch: 213 out of 296\n",
      "Batch: 214 out of 296\n",
      "Batch: 215 out of 296\n",
      "Batch: 216 out of 296\n",
      "Batch: 217 out of 296\n",
      "Batch: 218 out of 296\n",
      "Batch: 219 out of 296\n",
      "Batch: 220 out of 296\n",
      "Batch: 221 out of 296\n",
      "Batch: 222 out of 296\n",
      "Batch: 223 out of 296\n",
      "Batch: 224 out of 296\n",
      "Batch: 225 out of 296\n",
      "Batch: 226 out of 296\n",
      "Batch: 227 out of 296\n",
      "Batch: 228 out of 296\n",
      "Batch: 229 out of 296\n",
      "Batch: 230 out of 296\n",
      "Batch: 231 out of 296\n",
      "Batch: 232 out of 296\n",
      "Batch: 233 out of 296\n",
      "Batch: 234 out of 296\n",
      "Batch: 235 out of 296\n",
      "Batch: 236 out of 296\n",
      "Batch: 237 out of 296\n",
      "Batch: 238 out of 296\n",
      "Batch: 239 out of 296\n",
      "Batch: 240 out of 296\n",
      "Batch: 241 out of 296\n",
      "Batch: 242 out of 296\n",
      "Batch: 243 out of 296\n",
      "Batch: 244 out of 296\n",
      "Batch: 245 out of 296\n",
      "Batch: 246 out of 296\n",
      "Batch: 247 out of 296\n",
      "Batch: 248 out of 296\n",
      "Batch: 249 out of 296\n",
      "Batch: 250 out of 296\n",
      "Batch: 251 out of 296\n",
      "Batch: 252 out of 296\n",
      "Batch: 253 out of 296\n",
      "Batch: 254 out of 296\n",
      "Batch: 255 out of 296\n",
      "Batch: 256 out of 296\n",
      "Batch: 257 out of 296\n",
      "Batch: 258 out of 296\n",
      "Batch: 259 out of 296\n",
      "Batch: 260 out of 296\n",
      "Batch: 261 out of 296\n",
      "Batch: 262 out of 296\n",
      "Batch: 263 out of 296\n",
      "Batch: 264 out of 296\n",
      "Batch: 265 out of 296\n",
      "Batch: 266 out of 296\n",
      "Batch: 267 out of 296\n",
      "Batch: 268 out of 296\n",
      "Batch: 269 out of 296\n",
      "Batch: 270 out of 296\n",
      "Batch: 271 out of 296\n",
      "Batch: 272 out of 296\n",
      "Batch: 273 out of 296\n",
      "Batch: 274 out of 296\n",
      "Batch: 275 out of 296\n",
      "Batch: 276 out of 296\n",
      "Batch: 277 out of 296\n",
      "Batch: 278 out of 296\n",
      "Batch: 279 out of 296\n",
      "Batch: 280 out of 296\n",
      "Batch: 281 out of 296\n",
      "Batch: 282 out of 296\n",
      "Batch: 283 out of 296\n",
      "Batch: 284 out of 296\n",
      "Batch: 285 out of 296\n",
      "Batch: 286 out of 296\n",
      "Batch: 287 out of 296\n",
      "Batch: 288 out of 296\n",
      "Batch: 289 out of 296\n",
      "Batch: 290 out of 296\n",
      "Batch: 291 out of 296\n",
      "Batch: 292 out of 296\n",
      "Batch: 293 out of 296\n",
      "Batch: 294 out of 296\n",
      "Batch: 295 out of 296\n",
      "Batch: 296 out of 296\n",
      "Finished Epoch 1 Training in 10.98 minutes\n",
      "Batch: 1 out of 127\n",
      "Batch: 2 out of 127\n",
      "Batch: 3 out of 127\n",
      "Batch: 4 out of 127\n",
      "Batch: 5 out of 127\n",
      "Batch: 6 out of 127\n",
      "Batch: 7 out of 127\n",
      "Batch: 8 out of 127\n",
      "Batch: 9 out of 127\n",
      "Batch: 10 out of 127\n",
      "Batch: 11 out of 127\n",
      "Batch: 12 out of 127\n",
      "Batch: 13 out of 127\n",
      "Batch: 14 out of 127\n",
      "Batch: 15 out of 127\n",
      "Batch: 16 out of 127\n",
      "Batch: 17 out of 127\n",
      "Batch: 18 out of 127\n",
      "Batch: 19 out of 127\n",
      "Batch: 20 out of 127\n",
      "Batch: 21 out of 127\n",
      "Batch: 22 out of 127\n",
      "Batch: 23 out of 127\n",
      "Batch: 24 out of 127\n",
      "Batch: 25 out of 127\n",
      "Batch: 26 out of 127\n",
      "Batch: 27 out of 127\n",
      "Batch: 28 out of 127\n",
      "Batch: 29 out of 127\n",
      "Batch: 30 out of 127\n",
      "Batch: 31 out of 127\n",
      "Batch: 32 out of 127\n",
      "Batch: 33 out of 127\n",
      "Batch: 34 out of 127\n",
      "Batch: 35 out of 127\n",
      "Batch: 36 out of 127\n",
      "Batch: 37 out of 127\n",
      "Batch: 38 out of 127\n",
      "Batch: 39 out of 127\n",
      "Batch: 40 out of 127\n",
      "Batch: 41 out of 127\n",
      "Batch: 42 out of 127\n",
      "Batch: 43 out of 127\n",
      "Batch: 44 out of 127\n",
      "Batch: 45 out of 127\n",
      "Batch: 46 out of 127\n",
      "Batch: 47 out of 127\n",
      "Batch: 48 out of 127\n",
      "Batch: 49 out of 127\n",
      "Batch: 50 out of 127\n",
      "Batch: 51 out of 127\n",
      "Batch: 52 out of 127\n",
      "Batch: 53 out of 127\n",
      "Batch: 54 out of 127\n",
      "Batch: 55 out of 127\n",
      "Batch: 56 out of 127\n",
      "Batch: 57 out of 127\n",
      "Batch: 58 out of 127\n",
      "Batch: 59 out of 127\n",
      "Batch: 60 out of 127\n",
      "Batch: 61 out of 127\n",
      "Batch: 62 out of 127\n",
      "Batch: 63 out of 127\n",
      "Batch: 64 out of 127\n",
      "Batch: 65 out of 127\n",
      "Batch: 66 out of 127\n",
      "Batch: 67 out of 127\n",
      "Batch: 68 out of 127\n",
      "Batch: 69 out of 127\n",
      "Batch: 70 out of 127\n",
      "Batch: 71 out of 127\n",
      "Batch: 72 out of 127\n",
      "Batch: 73 out of 127\n",
      "Batch: 74 out of 127\n",
      "Batch: 75 out of 127\n",
      "Batch: 76 out of 127\n",
      "Batch: 77 out of 127\n",
      "Batch: 78 out of 127\n",
      "Batch: 79 out of 127\n",
      "Batch: 80 out of 127\n",
      "Batch: 81 out of 127\n",
      "Batch: 82 out of 127\n",
      "Batch: 83 out of 127\n",
      "Batch: 84 out of 127\n",
      "Batch: 85 out of 127\n",
      "Batch: 86 out of 127\n",
      "Batch: 87 out of 127\n",
      "Batch: 88 out of 127\n",
      "Batch: 89 out of 127\n",
      "Batch: 90 out of 127\n",
      "Batch: 91 out of 127\n",
      "Batch: 92 out of 127\n",
      "Batch: 93 out of 127\n",
      "Batch: 94 out of 127\n",
      "Batch: 95 out of 127\n",
      "Batch: 96 out of 127\n",
      "Batch: 97 out of 127\n",
      "Batch: 98 out of 127\n",
      "Batch: 99 out of 127\n",
      "Batch: 100 out of 127\n",
      "Batch: 101 out of 127\n",
      "Batch: 102 out of 127\n",
      "Batch: 103 out of 127\n",
      "Batch: 104 out of 127\n",
      "Batch: 105 out of 127\n",
      "Batch: 106 out of 127\n",
      "Batch: 107 out of 127\n",
      "Batch: 108 out of 127\n",
      "Batch: 109 out of 127\n",
      "Batch: 110 out of 127\n",
      "Batch: 111 out of 127\n",
      "Batch: 112 out of 127\n",
      "Batch: 113 out of 127\n",
      "Batch: 114 out of 127\n",
      "Batch: 115 out of 127\n",
      "Batch: 116 out of 127\n",
      "Batch: 117 out of 127\n",
      "Batch: 118 out of 127\n",
      "Batch: 119 out of 127\n",
      "Batch: 120 out of 127\n",
      "Batch: 121 out of 127\n",
      "Batch: 122 out of 127\n",
      "Batch: 123 out of 127\n",
      "Batch: 124 out of 127\n",
      "Batch: 125 out of 127\n",
      "Batch: 126 out of 127\n",
      "Batch: 127 out of 127\n",
      "tensor([[408.,  91.,  17.,   1.,  61.,  34.,   0.,   7.],\n",
      "        [ 58., 689.,   3.,   8.,   9.,   4.,   0.,   7.],\n",
      "        [  5.,   0.,  93.,  13.,   4.,   2.,   0.,   1.],\n",
      "        [  0.,   1.,  36., 112.,   2.,   2.,   0.,   1.],\n",
      "        [ 86.,  22.,  25.,   9., 561.,  38.,   2.,  24.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
      "        [  0.,   0.,   1.,  10.,   3.,   0., 211.,  28.],\n",
      "        [139., 222.,  15.,  14.,  77.,  34.,  26., 843.]])\n",
      "Class 1\n",
      "TP 408.0, TN 3152.0, FP 211.0, FN 288.0\n",
      "Sensitivity or Recall = 0.5862069129943848\n",
      "Specificity = 0.9372584223747253\n",
      "Precision = 0.5862069129943848\n",
      "F1 Score = 0.5862069129943848\n",
      "Class 2\n",
      "TP 689.0, TN 2945.0, FP 89.0, FN 336.0\n",
      "Sensitivity or Recall = 0.6721951365470886\n",
      "Specificity = 0.9706658124923706\n",
      "Precision = 0.6721951365470886\n",
      "F1 Score = 0.6721951365470886\n",
      "Class 3\n",
      "TP 93.0, TN 3844.0, FP 25.0, FN 97.0\n",
      "Sensitivity or Recall = 0.4894736707210541\n",
      "Specificity = 0.9935383796691895\n",
      "Precision = 0.4894736707210541\n",
      "F1 Score = 0.4894736707210541\n",
      "Class 4\n",
      "TP 112.0, TN 3850.0, FP 42.0, FN 55.0\n",
      "Sensitivity or Recall = 0.6706587076187134\n",
      "Specificity = 0.9892086386680603\n",
      "Precision = 0.6706587076187134\n",
      "F1 Score = 0.6706587076187134\n",
      "Class 5\n",
      "TP 561.0, TN 3136.0, FP 206.0, FN 156.0\n",
      "Sensitivity or Recall = 0.7824267745018005\n",
      "Specificity = 0.9383602738380432\n",
      "Precision = 0.7824267745018005\n",
      "F1 Score = 0.7824267745018005\n",
      "Class 6\n",
      "TP 0.0, TN 3945.0, FP 0.0, FN 114.0\n",
      "Sensitivity or Recall = 0.0\n",
      "Specificity = 1.0\n",
      "Precision = 0.0\n",
      "F1 Score = nan\n",
      "Class 7\n",
      "TP 211.0, TN 3778.0, FP 42.0, FN 28.0\n",
      "Sensitivity or Recall = 0.8828451633453369\n",
      "Specificity = 0.9890052080154419\n",
      "Precision = 0.8828451633453369\n",
      "F1 Score = 0.8828451633453369\n",
      "Class 8\n",
      "TP 843.0, TN 2621.0, FP 527.0, FN 68.0\n",
      "Sensitivity or Recall = 0.9253567457199097\n",
      "Specificity = 0.8325921297073364\n",
      "Precision = 0.9253567457199097\n",
      "F1 Score = 0.9253567457199097\n",
      "Finished Epoch 1 Validating in 4.09 minutes\n",
      "Record Accuracy 71.87226597718367  in epoch 1\n",
      "Accuracy: 71.872 %\n",
      "Training Loss: 1.135932 \tValidation Loss: 0.842117 \n",
      "\n",
      "Total Time is 15.07 minutes\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anupa\\AppData\\Local\\Temp\\ipykernel_1920\\2182347492.py:192: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen/native/IndexingUtils.h:30.)\n",
      "  FP = confusion_matrix[c, idx].sum()\n",
      "C:\\Users\\anupa\\AppData\\Local\\Temp\\ipykernel_1920\\2182347492.py:193: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen/native/IndexingUtils.h:30.)\n",
      "  FN = confusion_matrix[idx, c].sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 1 out of 296\n",
      "Batch: 2 out of 296\n",
      "Batch: 3 out of 296\n",
      "Batch: 4 out of 296\n",
      "Batch: 5 out of 296\n",
      "Batch: 6 out of 296\n",
      "Batch: 7 out of 296\n",
      "Batch: 8 out of 296\n",
      "Batch: 9 out of 296\n",
      "Batch: 10 out of 296\n",
      "Batch: 11 out of 296\n",
      "Batch: 12 out of 296\n",
      "Batch: 13 out of 296\n",
      "Batch: 14 out of 296\n",
      "Batch: 15 out of 296\n",
      "Batch: 16 out of 296\n",
      "Batch: 17 out of 296\n",
      "Batch: 18 out of 296\n",
      "Batch: 19 out of 296\n",
      "Batch: 20 out of 296\n",
      "Batch: 21 out of 296\n",
      "Batch: 22 out of 296\n",
      "Batch: 23 out of 296\n",
      "Batch: 24 out of 296\n",
      "Batch: 25 out of 296\n",
      "Batch: 26 out of 296\n",
      "Batch: 27 out of 296\n",
      "Batch: 28 out of 296\n",
      "Batch: 29 out of 296\n",
      "Batch: 30 out of 296\n",
      "Batch: 31 out of 296\n",
      "Batch: 32 out of 296\n",
      "Batch: 33 out of 296\n",
      "Batch: 34 out of 296\n",
      "Batch: 35 out of 296\n",
      "Batch: 36 out of 296\n",
      "Batch: 37 out of 296\n",
      "Batch: 38 out of 296\n",
      "Batch: 39 out of 296\n",
      "Batch: 40 out of 296\n",
      "Batch: 41 out of 296\n",
      "Batch: 42 out of 296\n",
      "Batch: 43 out of 296\n",
      "Batch: 44 out of 296\n",
      "Batch: 45 out of 296\n",
      "Batch: 46 out of 296\n",
      "Batch: 47 out of 296\n",
      "Batch: 48 out of 296\n",
      "Batch: 49 out of 296\n",
      "Batch: 50 out of 296\n",
      "Batch: 51 out of 296\n",
      "Batch: 52 out of 296\n",
      "Batch: 53 out of 296\n",
      "Batch: 54 out of 296\n",
      "Batch: 55 out of 296\n",
      "Batch: 56 out of 296\n",
      "Batch: 57 out of 296\n",
      "Batch: 58 out of 296\n",
      "Batch: 59 out of 296\n",
      "Batch: 60 out of 296\n",
      "Batch: 61 out of 296\n",
      "Batch: 62 out of 296\n",
      "Batch: 63 out of 296\n",
      "Batch: 64 out of 296\n",
      "Batch: 65 out of 296\n",
      "Batch: 66 out of 296\n",
      "Batch: 67 out of 296\n",
      "Batch: 68 out of 296\n",
      "Batch: 69 out of 296\n",
      "Batch: 70 out of 296\n",
      "Batch: 71 out of 296\n",
      "Batch: 72 out of 296\n",
      "Batch: 73 out of 296\n",
      "Batch: 74 out of 296\n",
      "Batch: 75 out of 296\n",
      "Batch: 76 out of 296\n",
      "Batch: 77 out of 296\n",
      "Batch: 78 out of 296\n",
      "Batch: 79 out of 296\n",
      "Batch: 80 out of 296\n",
      "Batch: 81 out of 296\n",
      "Batch: 82 out of 296\n",
      "Batch: 83 out of 296\n",
      "Batch: 84 out of 296\n",
      "Batch: 85 out of 296\n",
      "Batch: 86 out of 296\n",
      "Batch: 87 out of 296\n",
      "Batch: 88 out of 296\n",
      "Batch: 89 out of 296\n",
      "Batch: 90 out of 296\n",
      "Batch: 91 out of 296\n",
      "Batch: 92 out of 296\n",
      "Batch: 93 out of 296\n",
      "Batch: 94 out of 296\n",
      "Batch: 95 out of 296\n",
      "Batch: 96 out of 296\n",
      "Batch: 97 out of 296\n",
      "Batch: 98 out of 296\n",
      "Batch: 99 out of 296\n",
      "Batch: 100 out of 296\n",
      "Batch: 101 out of 296\n",
      "Batch: 102 out of 296\n",
      "Batch: 103 out of 296\n",
      "Batch: 104 out of 296\n",
      "Batch: 105 out of 296\n",
      "Batch: 106 out of 296\n",
      "Batch: 107 out of 296\n",
      "Batch: 108 out of 296\n",
      "Batch: 109 out of 296\n",
      "Batch: 110 out of 296\n",
      "Batch: 111 out of 296\n",
      "Batch: 112 out of 296\n",
      "Batch: 113 out of 296\n",
      "Batch: 114 out of 296\n",
      "Batch: 115 out of 296\n",
      "Batch: 116 out of 296\n",
      "Batch: 117 out of 296\n",
      "Batch: 118 out of 296\n",
      "Batch: 119 out of 296\n",
      "Batch: 120 out of 296\n",
      "Batch: 121 out of 296\n",
      "Batch: 122 out of 296\n",
      "Batch: 123 out of 296\n",
      "Batch: 124 out of 296\n",
      "Batch: 125 out of 296\n",
      "Batch: 126 out of 296\n",
      "Batch: 127 out of 296\n",
      "Batch: 128 out of 296\n",
      "Batch: 129 out of 296\n",
      "Batch: 130 out of 296\n",
      "Batch: 131 out of 296\n",
      "Batch: 132 out of 296\n",
      "Batch: 133 out of 296\n",
      "Batch: 134 out of 296\n",
      "Batch: 135 out of 296\n",
      "Batch: 136 out of 296\n",
      "Batch: 137 out of 296\n",
      "Batch: 138 out of 296\n",
      "Batch: 139 out of 296\n",
      "Batch: 140 out of 296\n",
      "Batch: 141 out of 296\n",
      "Batch: 142 out of 296\n",
      "Batch: 143 out of 296\n",
      "Batch: 144 out of 296\n",
      "Batch: 145 out of 296\n",
      "Batch: 146 out of 296\n",
      "Batch: 147 out of 296\n",
      "Batch: 148 out of 296\n",
      "Batch: 149 out of 296\n",
      "Batch: 150 out of 296\n",
      "Batch: 151 out of 296\n",
      "Batch: 152 out of 296\n",
      "Batch: 153 out of 296\n",
      "Batch: 154 out of 296\n",
      "Batch: 155 out of 296\n",
      "Batch: 156 out of 296\n",
      "Batch: 157 out of 296\n",
      "Batch: 158 out of 296\n",
      "Batch: 159 out of 296\n",
      "Batch: 160 out of 296\n",
      "Batch: 161 out of 296\n",
      "Batch: 162 out of 296\n",
      "Batch: 163 out of 296\n",
      "Batch: 164 out of 296\n",
      "Batch: 165 out of 296\n",
      "Batch: 166 out of 296\n",
      "Batch: 167 out of 296\n",
      "Batch: 168 out of 296\n",
      "Batch: 169 out of 296\n",
      "Batch: 170 out of 296\n",
      "Batch: 171 out of 296\n",
      "Batch: 172 out of 296\n",
      "Batch: 173 out of 296\n",
      "Batch: 174 out of 296\n",
      "Batch: 175 out of 296\n",
      "Batch: 176 out of 296\n",
      "Batch: 177 out of 296\n",
      "Batch: 178 out of 296\n",
      "Batch: 179 out of 296\n",
      "Batch: 180 out of 296\n",
      "Batch: 181 out of 296\n",
      "Batch: 182 out of 296\n",
      "Batch: 183 out of 296\n",
      "Batch: 184 out of 296\n",
      "Batch: 185 out of 296\n",
      "Batch: 186 out of 296\n",
      "Batch: 187 out of 296\n",
      "Batch: 188 out of 296\n",
      "Batch: 189 out of 296\n",
      "Batch: 190 out of 296\n",
      "Batch: 191 out of 296\n",
      "Batch: 192 out of 296\n",
      "Batch: 193 out of 296\n",
      "Batch: 194 out of 296\n",
      "Batch: 195 out of 296\n",
      "Batch: 196 out of 296\n",
      "Batch: 197 out of 296\n",
      "Batch: 198 out of 296\n",
      "Batch: 199 out of 296\n",
      "Batch: 200 out of 296\n",
      "Batch: 201 out of 296\n",
      "Batch: 202 out of 296\n",
      "Batch: 203 out of 296\n",
      "Batch: 204 out of 296\n",
      "Batch: 205 out of 296\n",
      "Batch: 206 out of 296\n",
      "Batch: 207 out of 296\n",
      "Batch: 208 out of 296\n",
      "Batch: 209 out of 296\n",
      "Batch: 210 out of 296\n",
      "Batch: 211 out of 296\n",
      "Batch: 212 out of 296\n",
      "Batch: 213 out of 296\n",
      "Batch: 214 out of 296\n",
      "Batch: 215 out of 296\n",
      "Batch: 216 out of 296\n",
      "Batch: 217 out of 296\n",
      "Batch: 218 out of 296\n",
      "Batch: 219 out of 296\n",
      "Batch: 220 out of 296\n",
      "Batch: 221 out of 296\n",
      "Batch: 222 out of 296\n",
      "Batch: 223 out of 296\n",
      "Batch: 224 out of 296\n",
      "Batch: 225 out of 296\n",
      "Batch: 226 out of 296\n",
      "Batch: 227 out of 296\n",
      "Batch: 228 out of 296\n",
      "Batch: 229 out of 296\n",
      "Batch: 230 out of 296\n",
      "Batch: 231 out of 296\n",
      "Batch: 232 out of 296\n",
      "Batch: 233 out of 296\n",
      "Batch: 234 out of 296\n",
      "Batch: 235 out of 296\n",
      "Batch: 236 out of 296\n",
      "Batch: 237 out of 296\n",
      "Batch: 238 out of 296\n",
      "Batch: 239 out of 296\n",
      "Batch: 240 out of 296\n",
      "Batch: 241 out of 296\n",
      "Batch: 242 out of 296\n",
      "Batch: 243 out of 296\n",
      "Batch: 244 out of 296\n",
      "Batch: 245 out of 296\n",
      "Batch: 246 out of 296\n",
      "Batch: 247 out of 296\n",
      "Batch: 248 out of 296\n",
      "Batch: 249 out of 296\n",
      "Batch: 250 out of 296\n",
      "Batch: 251 out of 296\n",
      "Batch: 252 out of 296\n",
      "Batch: 253 out of 296\n",
      "Batch: 254 out of 296\n",
      "Batch: 255 out of 296\n",
      "Batch: 256 out of 296\n",
      "Batch: 257 out of 296\n",
      "Batch: 258 out of 296\n",
      "Batch: 259 out of 296\n",
      "Batch: 260 out of 296\n",
      "Batch: 261 out of 296\n",
      "Batch: 262 out of 296\n",
      "Batch: 263 out of 296\n",
      "Batch: 264 out of 296\n",
      "Batch: 265 out of 296\n",
      "Batch: 266 out of 296\n",
      "Batch: 267 out of 296\n",
      "Batch: 268 out of 296\n",
      "Batch: 269 out of 296\n",
      "Batch: 270 out of 296\n",
      "Batch: 271 out of 296\n",
      "Batch: 272 out of 296\n",
      "Batch: 273 out of 296\n",
      "Batch: 274 out of 296\n",
      "Batch: 275 out of 296\n",
      "Batch: 276 out of 296\n",
      "Batch: 277 out of 296\n",
      "Batch: 278 out of 296\n",
      "Batch: 279 out of 296\n",
      "Batch: 280 out of 296\n",
      "Batch: 281 out of 296\n",
      "Batch: 282 out of 296\n",
      "Batch: 283 out of 296\n",
      "Batch: 284 out of 296\n",
      "Batch: 285 out of 296\n",
      "Batch: 286 out of 296\n",
      "Batch: 287 out of 296\n",
      "Batch: 288 out of 296\n",
      "Batch: 289 out of 296\n",
      "Batch: 290 out of 296\n",
      "Batch: 291 out of 296\n",
      "Batch: 292 out of 296\n",
      "Batch: 293 out of 296\n",
      "Batch: 294 out of 296\n",
      "Batch: 295 out of 296\n",
      "Batch: 296 out of 296\n",
      "Finished Epoch 2 Training in 25.42 minutes\n",
      "Batch: 1 out of 127\n",
      "Batch: 2 out of 127\n",
      "Batch: 3 out of 127\n",
      "Batch: 4 out of 127\n",
      "Batch: 5 out of 127\n",
      "Batch: 6 out of 127\n",
      "Batch: 7 out of 127\n",
      "Batch: 8 out of 127\n",
      "Batch: 9 out of 127\n",
      "Batch: 10 out of 127\n",
      "Batch: 11 out of 127\n",
      "Batch: 12 out of 127\n",
      "Batch: 13 out of 127\n",
      "Batch: 14 out of 127\n",
      "Batch: 15 out of 127\n",
      "Batch: 16 out of 127\n",
      "Batch: 17 out of 127\n",
      "Batch: 18 out of 127\n",
      "Batch: 19 out of 127\n",
      "Batch: 20 out of 127\n",
      "Batch: 21 out of 127\n",
      "Batch: 22 out of 127\n",
      "Batch: 23 out of 127\n",
      "Batch: 24 out of 127\n",
      "Batch: 25 out of 127\n",
      "Batch: 26 out of 127\n",
      "Batch: 27 out of 127\n",
      "Batch: 28 out of 127\n",
      "Batch: 29 out of 127\n",
      "Batch: 30 out of 127\n",
      "Batch: 31 out of 127\n",
      "Batch: 32 out of 127\n",
      "Batch: 33 out of 127\n",
      "Batch: 34 out of 127\n",
      "Batch: 35 out of 127\n",
      "Batch: 36 out of 127\n",
      "Batch: 37 out of 127\n",
      "Batch: 38 out of 127\n",
      "Batch: 39 out of 127\n",
      "Batch: 40 out of 127\n",
      "Batch: 41 out of 127\n",
      "Batch: 42 out of 127\n",
      "Batch: 43 out of 127\n",
      "Batch: 44 out of 127\n",
      "Batch: 45 out of 127\n",
      "Batch: 46 out of 127\n",
      "Batch: 47 out of 127\n",
      "Batch: 48 out of 127\n",
      "Batch: 49 out of 127\n",
      "Batch: 50 out of 127\n",
      "Batch: 51 out of 127\n",
      "Batch: 52 out of 127\n",
      "Batch: 53 out of 127\n",
      "Batch: 54 out of 127\n",
      "Batch: 55 out of 127\n",
      "Batch: 56 out of 127\n",
      "Batch: 57 out of 127\n",
      "Batch: 58 out of 127\n",
      "Batch: 59 out of 127\n",
      "Batch: 60 out of 127\n",
      "Batch: 61 out of 127\n",
      "Batch: 62 out of 127\n",
      "Batch: 63 out of 127\n",
      "Batch: 64 out of 127\n",
      "Batch: 65 out of 127\n",
      "Batch: 66 out of 127\n",
      "Batch: 67 out of 127\n",
      "Batch: 68 out of 127\n",
      "Batch: 69 out of 127\n",
      "Batch: 70 out of 127\n",
      "Batch: 71 out of 127\n",
      "Batch: 72 out of 127\n",
      "Batch: 73 out of 127\n",
      "Batch: 74 out of 127\n",
      "Batch: 75 out of 127\n",
      "Batch: 76 out of 127\n",
      "Batch: 77 out of 127\n",
      "Batch: 78 out of 127\n",
      "Batch: 79 out of 127\n",
      "Batch: 80 out of 127\n",
      "Batch: 81 out of 127\n",
      "Batch: 82 out of 127\n",
      "Batch: 83 out of 127\n",
      "Batch: 84 out of 127\n",
      "Batch: 85 out of 127\n",
      "Batch: 86 out of 127\n",
      "Batch: 87 out of 127\n",
      "Batch: 88 out of 127\n",
      "Batch: 89 out of 127\n",
      "Batch: 90 out of 127\n",
      "Batch: 91 out of 127\n",
      "Batch: 92 out of 127\n",
      "Batch: 93 out of 127\n",
      "Batch: 94 out of 127\n",
      "Batch: 95 out of 127\n",
      "Batch: 96 out of 127\n",
      "Batch: 97 out of 127\n",
      "Batch: 98 out of 127\n",
      "Batch: 99 out of 127\n",
      "Batch: 100 out of 127\n",
      "Batch: 101 out of 127\n",
      "Batch: 102 out of 127\n",
      "Batch: 103 out of 127\n",
      "Batch: 104 out of 127\n",
      "Batch: 105 out of 127\n",
      "Batch: 106 out of 127\n",
      "Batch: 107 out of 127\n",
      "Batch: 108 out of 127\n",
      "Batch: 109 out of 127\n",
      "Batch: 110 out of 127\n",
      "Batch: 111 out of 127\n",
      "Batch: 112 out of 127\n",
      "Batch: 113 out of 127\n",
      "Batch: 114 out of 127\n",
      "Batch: 115 out of 127\n",
      "Batch: 116 out of 127\n",
      "Batch: 117 out of 127\n",
      "Batch: 118 out of 127\n",
      "Batch: 119 out of 127\n",
      "Batch: 120 out of 127\n",
      "Batch: 121 out of 127\n",
      "Batch: 122 out of 127\n",
      "Batch: 123 out of 127\n",
      "Batch: 124 out of 127\n",
      "Batch: 125 out of 127\n",
      "Batch: 126 out of 127\n",
      "Batch: 127 out of 127\n",
      "tensor([[451.,  57.,  16.,   1.,  77.,  37.,   0.,  19.],\n",
      "        [139., 883.,   9.,  10.,  27.,  11.,   0.,  63.],\n",
      "        [  5.,   0., 115.,  23.,   7.,   5.,   0.,   2.],\n",
      "        [  0.,   1.,  33., 126.,   1.,   3.,   2.,  13.],\n",
      "        [ 52.,  14.,  16.,   5., 572.,  40.,   3.,  26.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0., 215.,   8.],\n",
      "        [ 49.,  70.,   1.,   2.,  33.,  18.,  19., 780.]])\n",
      "Class 1\n",
      "TP 451.0, TN 3156.0, FP 207.0, FN 245.0\n",
      "Sensitivity or Recall = 0.647988498210907\n",
      "Specificity = 0.9384478330612183\n",
      "Precision = 0.647988498210907\n",
      "F1 Score = 0.647988498210907\n",
      "Class 2\n",
      "TP 883.0, TN 2775.0, FP 259.0, FN 142.0\n",
      "Sensitivity or Recall = 0.8614634275436401\n",
      "Specificity = 0.9146341681480408\n",
      "Precision = 0.8614634275436401\n",
      "F1 Score = 0.8614634275436401\n",
      "Class 3\n",
      "TP 115.0, TN 3827.0, FP 42.0, FN 75.0\n",
      "Sensitivity or Recall = 0.6052631735801697\n",
      "Specificity = 0.989144504070282\n",
      "Precision = 0.6052631735801697\n",
      "F1 Score = 0.6052631735801697\n",
      "Class 4\n",
      "TP 126.0, TN 3839.0, FP 53.0, FN 41.0\n",
      "Sensitivity or Recall = 0.7544910311698914\n",
      "Specificity = 0.9863823056221008\n",
      "Precision = 0.7544910311698914\n",
      "F1 Score = 0.7544910311698914\n",
      "Class 5\n",
      "TP 572.0, TN 3186.0, FP 156.0, FN 145.0\n",
      "Sensitivity or Recall = 0.7977684736251831\n",
      "Specificity = 0.9533213376998901\n",
      "Precision = 0.7977684736251831\n",
      "F1 Score = 0.7977684736251831\n",
      "Class 6\n",
      "TP 0.0, TN 3945.0, FP 0.0, FN 114.0\n",
      "Sensitivity or Recall = 0.0\n",
      "Specificity = 1.0\n",
      "Precision = 0.0\n",
      "F1 Score = nan\n",
      "Class 7\n",
      "TP 215.0, TN 3812.0, FP 8.0, FN 24.0\n",
      "Sensitivity or Recall = 0.8995816111564636\n",
      "Specificity = 0.9979057312011719\n",
      "Precision = 0.8995816111564636\n",
      "F1 Score = 0.8995816111564636\n",
      "Class 8\n",
      "TP 780.0, TN 2956.0, FP 192.0, FN 131.0\n",
      "Sensitivity or Recall = 0.8562019467353821\n",
      "Specificity = 0.939008891582489\n",
      "Precision = 0.8562019467353821\n",
      "F1 Score = 0.8562019467353821\n",
      "Finished Epoch 2 Validating in 3.72 minutes\n",
      "Record Accuracy 77.40412654839163  in epoch 2\n",
      "Accuracy: 77.404 %\n",
      "Training Loss: 0.711776 \tValidation Loss: 0.661376 \n",
      "\n",
      "Total Time is 29.14 minutes\n",
      "Epoch: 3\n",
      "Batch: 1 out of 296\n",
      "Batch: 2 out of 296\n",
      "Batch: 3 out of 296\n",
      "Batch: 4 out of 296\n",
      "Batch: 5 out of 296\n",
      "Batch: 6 out of 296\n",
      "Batch: 7 out of 296\n",
      "Batch: 8 out of 296\n",
      "Batch: 9 out of 296\n",
      "Batch: 10 out of 296\n",
      "Batch: 11 out of 296\n",
      "Batch: 12 out of 296\n",
      "Batch: 13 out of 296\n",
      "Batch: 14 out of 296\n",
      "Batch: 15 out of 296\n",
      "Batch: 16 out of 296\n",
      "Batch: 17 out of 296\n",
      "Batch: 18 out of 296\n",
      "Batch: 19 out of 296\n",
      "Batch: 20 out of 296\n",
      "Batch: 21 out of 296\n",
      "Batch: 22 out of 296\n",
      "Batch: 23 out of 296\n",
      "Batch: 24 out of 296\n",
      "Batch: 25 out of 296\n",
      "Batch: 26 out of 296\n",
      "Batch: 27 out of 296\n",
      "Batch: 28 out of 296\n",
      "Batch: 29 out of 296\n",
      "Batch: 30 out of 296\n",
      "Batch: 31 out of 296\n",
      "Batch: 32 out of 296\n",
      "Batch: 33 out of 296\n",
      "Batch: 34 out of 296\n",
      "Batch: 35 out of 296\n",
      "Batch: 36 out of 296\n",
      "Batch: 37 out of 296\n",
      "Batch: 38 out of 296\n",
      "Batch: 39 out of 296\n",
      "Batch: 40 out of 296\n",
      "Batch: 41 out of 296\n",
      "Batch: 42 out of 296\n",
      "Batch: 43 out of 296\n",
      "Batch: 44 out of 296\n",
      "Batch: 45 out of 296\n",
      "Batch: 46 out of 296\n",
      "Batch: 47 out of 296\n",
      "Batch: 48 out of 296\n",
      "Batch: 49 out of 296\n",
      "Batch: 50 out of 296\n",
      "Batch: 51 out of 296\n",
      "Batch: 52 out of 296\n",
      "Batch: 53 out of 296\n",
      "Batch: 54 out of 296\n",
      "Batch: 55 out of 296\n",
      "Batch: 56 out of 296\n",
      "Batch: 57 out of 296\n",
      "Batch: 58 out of 296\n",
      "Batch: 59 out of 296\n",
      "Batch: 60 out of 296\n",
      "Batch: 61 out of 296\n",
      "Batch: 62 out of 296\n",
      "Batch: 63 out of 296\n",
      "Batch: 64 out of 296\n",
      "Batch: 65 out of 296\n",
      "Batch: 66 out of 296\n",
      "Batch: 67 out of 296\n",
      "Batch: 68 out of 296\n",
      "Batch: 69 out of 296\n",
      "Batch: 70 out of 296\n",
      "Batch: 71 out of 296\n",
      "Batch: 72 out of 296\n",
      "Batch: 73 out of 296\n",
      "Batch: 74 out of 296\n",
      "Batch: 75 out of 296\n",
      "Batch: 76 out of 296\n",
      "Batch: 77 out of 296\n",
      "Batch: 78 out of 296\n",
      "Batch: 79 out of 296\n",
      "Batch: 80 out of 296\n",
      "Batch: 81 out of 296\n",
      "Batch: 82 out of 296\n",
      "Batch: 83 out of 296\n",
      "Batch: 84 out of 296\n",
      "Batch: 85 out of 296\n",
      "Batch: 86 out of 296\n",
      "Batch: 87 out of 296\n",
      "Batch: 88 out of 296\n",
      "Batch: 89 out of 296\n",
      "Batch: 90 out of 296\n",
      "Batch: 91 out of 296\n",
      "Batch: 92 out of 296\n",
      "Batch: 93 out of 296\n",
      "Batch: 94 out of 296\n",
      "Batch: 95 out of 296\n",
      "Batch: 96 out of 296\n",
      "Batch: 97 out of 296\n",
      "Batch: 98 out of 296\n",
      "Batch: 99 out of 296\n",
      "Batch: 100 out of 296\n",
      "Batch: 101 out of 296\n",
      "Batch: 102 out of 296\n",
      "Batch: 103 out of 296\n",
      "Batch: 104 out of 296\n",
      "Batch: 105 out of 296\n",
      "Batch: 106 out of 296\n",
      "Batch: 107 out of 296\n",
      "Batch: 108 out of 296\n",
      "Batch: 109 out of 296\n",
      "Batch: 110 out of 296\n",
      "Batch: 111 out of 296\n",
      "Batch: 112 out of 296\n",
      "Batch: 113 out of 296\n",
      "Batch: 114 out of 296\n",
      "Batch: 115 out of 296\n",
      "Batch: 116 out of 296\n",
      "Batch: 117 out of 296\n",
      "Batch: 118 out of 296\n",
      "Batch: 119 out of 296\n",
      "Batch: 120 out of 296\n",
      "Batch: 121 out of 296\n",
      "Batch: 122 out of 296\n",
      "Batch: 123 out of 296\n",
      "Batch: 124 out of 296\n",
      "Batch: 125 out of 296\n",
      "Batch: 126 out of 296\n",
      "Batch: 127 out of 296\n",
      "Batch: 128 out of 296\n",
      "Batch: 129 out of 296\n",
      "Batch: 130 out of 296\n",
      "Batch: 131 out of 296\n",
      "Batch: 132 out of 296\n",
      "Batch: 133 out of 296\n",
      "Batch: 134 out of 296\n",
      "Batch: 135 out of 296\n",
      "Batch: 136 out of 296\n",
      "Batch: 137 out of 296\n",
      "Batch: 138 out of 296\n",
      "Batch: 139 out of 296\n",
      "Batch: 140 out of 296\n",
      "Batch: 141 out of 296\n",
      "Batch: 142 out of 296\n",
      "Batch: 143 out of 296\n",
      "Batch: 144 out of 296\n",
      "Batch: 145 out of 296\n",
      "Batch: 146 out of 296\n",
      "Batch: 147 out of 296\n",
      "Batch: 148 out of 296\n",
      "Batch: 149 out of 296\n",
      "Batch: 150 out of 296\n",
      "Batch: 151 out of 296\n",
      "Batch: 152 out of 296\n",
      "Batch: 153 out of 296\n",
      "Batch: 154 out of 296\n",
      "Batch: 155 out of 296\n",
      "Batch: 156 out of 296\n",
      "Batch: 157 out of 296\n",
      "Batch: 158 out of 296\n",
      "Batch: 159 out of 296\n",
      "Batch: 160 out of 296\n",
      "Batch: 161 out of 296\n",
      "Batch: 162 out of 296\n",
      "Batch: 163 out of 296\n",
      "Batch: 164 out of 296\n",
      "Batch: 165 out of 296\n",
      "Batch: 166 out of 296\n",
      "Batch: 167 out of 296\n",
      "Batch: 168 out of 296\n",
      "Batch: 169 out of 296\n",
      "Batch: 170 out of 296\n",
      "Batch: 171 out of 296\n",
      "Batch: 172 out of 296\n",
      "Batch: 173 out of 296\n",
      "Batch: 174 out of 296\n",
      "Batch: 175 out of 296\n",
      "Batch: 176 out of 296\n",
      "Batch: 177 out of 296\n",
      "Batch: 178 out of 296\n",
      "Batch: 179 out of 296\n",
      "Batch: 180 out of 296\n",
      "Batch: 181 out of 296\n",
      "Batch: 182 out of 296\n",
      "Batch: 183 out of 296\n",
      "Batch: 184 out of 296\n",
      "Batch: 185 out of 296\n",
      "Batch: 186 out of 296\n",
      "Batch: 187 out of 296\n",
      "Batch: 188 out of 296\n",
      "Batch: 189 out of 296\n",
      "Batch: 190 out of 296\n",
      "Batch: 191 out of 296\n",
      "Batch: 192 out of 296\n",
      "Batch: 193 out of 296\n",
      "Batch: 194 out of 296\n",
      "Batch: 195 out of 296\n",
      "Batch: 196 out of 296\n",
      "Batch: 197 out of 296\n",
      "Batch: 198 out of 296\n",
      "Batch: 199 out of 296\n",
      "Batch: 200 out of 296\n",
      "Batch: 201 out of 296\n",
      "Batch: 202 out of 296\n",
      "Batch: 203 out of 296\n",
      "Batch: 204 out of 296\n",
      "Batch: 205 out of 296\n",
      "Batch: 206 out of 296\n",
      "Batch: 207 out of 296\n",
      "Batch: 208 out of 296\n",
      "Batch: 209 out of 296\n",
      "Batch: 210 out of 296\n",
      "Batch: 211 out of 296\n",
      "Batch: 212 out of 296\n",
      "Batch: 213 out of 296\n",
      "Batch: 214 out of 296\n",
      "Batch: 215 out of 296\n",
      "Batch: 216 out of 296\n",
      "Batch: 217 out of 296\n",
      "Batch: 218 out of 296\n",
      "Batch: 219 out of 296\n",
      "Batch: 220 out of 296\n",
      "Batch: 221 out of 296\n",
      "Batch: 222 out of 296\n",
      "Batch: 223 out of 296\n",
      "Batch: 224 out of 296\n",
      "Batch: 225 out of 296\n",
      "Batch: 226 out of 296\n",
      "Batch: 227 out of 296\n",
      "Batch: 228 out of 296\n",
      "Batch: 229 out of 296\n",
      "Batch: 230 out of 296\n",
      "Batch: 231 out of 296\n",
      "Batch: 232 out of 296\n",
      "Batch: 233 out of 296\n",
      "Batch: 234 out of 296\n",
      "Batch: 235 out of 296\n",
      "Batch: 236 out of 296\n",
      "Batch: 237 out of 296\n",
      "Batch: 238 out of 296\n",
      "Batch: 239 out of 296\n",
      "Batch: 240 out of 296\n",
      "Batch: 241 out of 296\n",
      "Batch: 242 out of 296\n",
      "Batch: 243 out of 296\n",
      "Batch: 244 out of 296\n",
      "Batch: 245 out of 296\n",
      "Batch: 246 out of 296\n",
      "Batch: 247 out of 296\n",
      "Batch: 248 out of 296\n",
      "Batch: 249 out of 296\n",
      "Batch: 250 out of 296\n",
      "Batch: 251 out of 296\n",
      "Batch: 252 out of 296\n",
      "Batch: 253 out of 296\n",
      "Batch: 254 out of 296\n",
      "Batch: 255 out of 296\n",
      "Batch: 256 out of 296\n",
      "Batch: 257 out of 296\n",
      "Batch: 258 out of 296\n",
      "Batch: 259 out of 296\n",
      "Batch: 260 out of 296\n",
      "Batch: 261 out of 296\n",
      "Batch: 262 out of 296\n",
      "Batch: 263 out of 296\n",
      "Batch: 264 out of 296\n",
      "Batch: 265 out of 296\n",
      "Batch: 266 out of 296\n",
      "Batch: 267 out of 296\n",
      "Batch: 268 out of 296\n",
      "Batch: 269 out of 296\n",
      "Batch: 270 out of 296\n",
      "Batch: 271 out of 296\n",
      "Batch: 272 out of 296\n",
      "Batch: 273 out of 296\n",
      "Batch: 274 out of 296\n",
      "Batch: 275 out of 296\n",
      "Batch: 276 out of 296\n",
      "Batch: 277 out of 296\n",
      "Batch: 278 out of 296\n",
      "Batch: 279 out of 296\n",
      "Batch: 280 out of 296\n",
      "Batch: 281 out of 296\n",
      "Batch: 282 out of 296\n",
      "Batch: 283 out of 296\n",
      "Batch: 284 out of 296\n",
      "Batch: 285 out of 296\n",
      "Batch: 286 out of 296\n",
      "Batch: 287 out of 296\n",
      "Batch: 288 out of 296\n",
      "Batch: 289 out of 296\n",
      "Batch: 290 out of 296\n",
      "Batch: 291 out of 296\n",
      "Batch: 292 out of 296\n",
      "Batch: 293 out of 296\n",
      "Batch: 294 out of 296\n",
      "Batch: 295 out of 296\n",
      "Batch: 296 out of 296\n",
      "Finished Epoch 3 Training in 38.87 minutes\n",
      "Batch: 1 out of 127\n",
      "Batch: 2 out of 127\n",
      "Batch: 3 out of 127\n",
      "Batch: 4 out of 127\n",
      "Batch: 5 out of 127\n",
      "Batch: 6 out of 127\n",
      "Batch: 7 out of 127\n",
      "Batch: 8 out of 127\n",
      "Batch: 9 out of 127\n",
      "Batch: 10 out of 127\n",
      "Batch: 11 out of 127\n",
      "Batch: 12 out of 127\n",
      "Batch: 13 out of 127\n",
      "Batch: 14 out of 127\n",
      "Batch: 15 out of 127\n",
      "Batch: 16 out of 127\n",
      "Batch: 17 out of 127\n",
      "Batch: 18 out of 127\n",
      "Batch: 19 out of 127\n",
      "Batch: 20 out of 127\n",
      "Batch: 21 out of 127\n",
      "Batch: 22 out of 127\n",
      "Batch: 23 out of 127\n",
      "Batch: 24 out of 127\n",
      "Batch: 25 out of 127\n",
      "Batch: 26 out of 127\n",
      "Batch: 27 out of 127\n",
      "Batch: 28 out of 127\n",
      "Batch: 29 out of 127\n",
      "Batch: 30 out of 127\n",
      "Batch: 31 out of 127\n",
      "Batch: 32 out of 127\n",
      "Batch: 33 out of 127\n",
      "Batch: 34 out of 127\n",
      "Batch: 35 out of 127\n",
      "Batch: 36 out of 127\n",
      "Batch: 37 out of 127\n",
      "Batch: 38 out of 127\n",
      "Batch: 39 out of 127\n",
      "Batch: 40 out of 127\n",
      "Batch: 41 out of 127\n",
      "Batch: 42 out of 127\n",
      "Batch: 43 out of 127\n",
      "Batch: 44 out of 127\n",
      "Batch: 45 out of 127\n",
      "Batch: 46 out of 127\n",
      "Batch: 47 out of 127\n",
      "Batch: 48 out of 127\n",
      "Batch: 49 out of 127\n",
      "Batch: 50 out of 127\n",
      "Batch: 51 out of 127\n",
      "Batch: 52 out of 127\n",
      "Batch: 53 out of 127\n",
      "Batch: 54 out of 127\n",
      "Batch: 55 out of 127\n",
      "Batch: 56 out of 127\n",
      "Batch: 57 out of 127\n",
      "Batch: 58 out of 127\n",
      "Batch: 59 out of 127\n",
      "Batch: 60 out of 127\n",
      "Batch: 61 out of 127\n",
      "Batch: 62 out of 127\n",
      "Batch: 63 out of 127\n",
      "Batch: 64 out of 127\n",
      "Batch: 65 out of 127\n",
      "Batch: 66 out of 127\n",
      "Batch: 67 out of 127\n",
      "Batch: 68 out of 127\n",
      "Batch: 69 out of 127\n",
      "Batch: 70 out of 127\n",
      "Batch: 71 out of 127\n",
      "Batch: 72 out of 127\n",
      "Batch: 73 out of 127\n",
      "Batch: 74 out of 127\n",
      "Batch: 75 out of 127\n",
      "Batch: 76 out of 127\n",
      "Batch: 77 out of 127\n",
      "Batch: 78 out of 127\n",
      "Batch: 79 out of 127\n",
      "Batch: 80 out of 127\n",
      "Batch: 81 out of 127\n",
      "Batch: 82 out of 127\n",
      "Batch: 83 out of 127\n",
      "Batch: 84 out of 127\n",
      "Batch: 85 out of 127\n",
      "Batch: 86 out of 127\n",
      "Batch: 87 out of 127\n",
      "Batch: 88 out of 127\n",
      "Batch: 89 out of 127\n",
      "Batch: 90 out of 127\n",
      "Batch: 91 out of 127\n",
      "Batch: 92 out of 127\n",
      "Batch: 93 out of 127\n",
      "Batch: 94 out of 127\n",
      "Batch: 95 out of 127\n",
      "Batch: 96 out of 127\n",
      "Batch: 97 out of 127\n",
      "Batch: 98 out of 127\n",
      "Batch: 99 out of 127\n",
      "Batch: 100 out of 127\n",
      "Batch: 101 out of 127\n",
      "Batch: 102 out of 127\n",
      "Batch: 103 out of 127\n",
      "Batch: 104 out of 127\n",
      "Batch: 105 out of 127\n",
      "Batch: 106 out of 127\n",
      "Batch: 107 out of 127\n",
      "Batch: 108 out of 127\n",
      "Batch: 109 out of 127\n",
      "Batch: 110 out of 127\n",
      "Batch: 111 out of 127\n",
      "Batch: 112 out of 127\n",
      "Batch: 113 out of 127\n",
      "Batch: 114 out of 127\n",
      "Batch: 115 out of 127\n",
      "Batch: 116 out of 127\n",
      "Batch: 117 out of 127\n",
      "Batch: 118 out of 127\n",
      "Batch: 119 out of 127\n",
      "Batch: 120 out of 127\n",
      "Batch: 121 out of 127\n",
      "Batch: 122 out of 127\n",
      "Batch: 123 out of 127\n",
      "Batch: 124 out of 127\n",
      "Batch: 125 out of 127\n",
      "Batch: 126 out of 127\n",
      "Batch: 127 out of 127\n",
      "tensor([[358.,  32.,   3.,   0.,  31.,  12.,   0.,   5.],\n",
      "        [165., 906.,   7.,   8.,  27.,  13.,   0.,  60.],\n",
      "        [ 11.,   1., 113.,  14.,   8.,   3.,   0.,   1.],\n",
      "        [  0.,   2.,  42., 136.,   4.,   4.,   1.,   6.],\n",
      "        [109.,  23.,  21.,   7., 623.,  56.,   3.,  38.],\n",
      "        [  4.,   0.,   1.,   0.,   0.,   8.,   0.,   2.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0., 221.,  12.],\n",
      "        [ 49.,  61.,   3.,   2.,  24.,  18.,  14., 787.]])\n",
      "Class 1\n",
      "TP 358.0, TN 3280.0, FP 83.0, FN 338.0\n",
      "Sensitivity or Recall = 0.5143678188323975\n",
      "Specificity = 0.9753196835517883\n",
      "Precision = 0.5143678188323975\n",
      "F1 Score = 0.5143678188323975\n",
      "Class 2\n",
      "TP 906.0, TN 2754.0, FP 280.0, FN 119.0\n",
      "Sensitivity or Recall = 0.8839024305343628\n",
      "Specificity = 0.9077125787734985\n",
      "Precision = 0.8839024305343628\n",
      "F1 Score = 0.8839024305343628\n",
      "Class 3\n",
      "TP 113.0, TN 3831.0, FP 38.0, FN 77.0\n",
      "Sensitivity or Recall = 0.5947368144989014\n",
      "Specificity = 0.9901783466339111\n",
      "Precision = 0.5947368144989014\n",
      "F1 Score = 0.5947368144989014\n",
      "Class 4\n",
      "TP 136.0, TN 3833.0, FP 59.0, FN 31.0\n",
      "Sensitivity or Recall = 0.8143712282180786\n",
      "Specificity = 0.9848406910896301\n",
      "Precision = 0.8143712282180786\n",
      "F1 Score = 0.8143712282180786\n",
      "Class 5\n",
      "TP 623.0, TN 3085.0, FP 257.0, FN 94.0\n",
      "Sensitivity or Recall = 0.8688982129096985\n",
      "Specificity = 0.923099935054779\n",
      "Precision = 0.8688982129096985\n",
      "F1 Score = 0.8688982129096985\n",
      "Class 6\n",
      "TP 8.0, TN 3938.0, FP 7.0, FN 106.0\n",
      "Sensitivity or Recall = 0.07017543911933899\n",
      "Specificity = 0.9982256293296814\n",
      "Precision = 0.07017543911933899\n",
      "F1 Score = 0.07017543911933899\n",
      "Class 7\n",
      "TP 221.0, TN 3808.0, FP 12.0, FN 18.0\n",
      "Sensitivity or Recall = 0.9246861934661865\n",
      "Specificity = 0.9968586564064026\n",
      "Precision = 0.9246861934661865\n",
      "F1 Score = 0.9246861934661865\n",
      "Class 8\n",
      "TP 787.0, TN 2977.0, FP 171.0, FN 124.0\n",
      "Sensitivity or Recall = 0.8638858199119568\n",
      "Specificity = 0.945679783821106\n",
      "Precision = 0.8638858199119568\n",
      "F1 Score = 0.8638858199119568\n",
      "Finished Epoch 3 Validating in 3.72 minutes\n",
      "Record Accuracy 77.65930299683819  in epoch 3\n",
      "Accuracy: 77.659 %\n",
      "Training Loss: 0.643359 \tValidation Loss: 0.663291 \n",
      "\n",
      "Total Time is 42.59 minutes\n",
      "Epoch: 4\n",
      "Batch: 1 out of 296\n",
      "Batch: 2 out of 296\n",
      "Batch: 3 out of 296\n",
      "Batch: 4 out of 296\n",
      "Batch: 5 out of 296\n",
      "Batch: 6 out of 296\n",
      "Batch: 7 out of 296\n",
      "Batch: 8 out of 296\n",
      "Batch: 9 out of 296\n",
      "Batch: 10 out of 296\n",
      "Batch: 11 out of 296\n",
      "Batch: 12 out of 296\n",
      "Batch: 13 out of 296\n",
      "Batch: 14 out of 296\n",
      "Batch: 15 out of 296\n",
      "Batch: 16 out of 296\n",
      "Batch: 17 out of 296\n",
      "Batch: 18 out of 296\n",
      "Batch: 19 out of 296\n",
      "Batch: 20 out of 296\n",
      "Batch: 21 out of 296\n",
      "Batch: 22 out of 296\n",
      "Batch: 23 out of 296\n",
      "Batch: 24 out of 296\n",
      "Batch: 25 out of 296\n"
     ]
    }
   ],
   "source": [
    "# Import Libraries\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from torch.quantization import quantize_dynamic\n",
    "\n",
    "# Specify transforms using torchvision.transforms as transforms library\n",
    "transformations = transforms.Compose([\n",
    "    transforms.Resize(255),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load in each dataset and apply transformations using the torchvision.datasets as datasets library\n",
    "train_set = datasets.ImageFolder(\"RDDC_Train\", transform=transformations)\n",
    "val_set = datasets.ImageFolder(\"RDDC_Test\", transform=transformations)\n",
    "\n",
    "print('The class labels are:', train_set.classes, '\\n')\n",
    "\n",
    "# Put into a Dataloader using torch library\n",
    "batch_size = 32\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Get pretrained model using torchvision.models as models library\n",
    "model = models.densenet161(pretrained=True)\n",
    "\n",
    "# Turn off training for their parameters\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Create new classifier for model using torch.nn as nn library\n",
    "classifier_input = model.classifier.in_features\n",
    "# classifier_input = 2208\n",
    "print(classifier_input)\n",
    "\n",
    "num_labels = 8\n",
    "classifier = nn.Sequential(nn.Linear(classifier_input, 64),\n",
    "                           nn.ReLU(),\n",
    "                           nn.Linear(64, 32),\n",
    "                           nn.ReLU(),\n",
    "                           nn.Linear(32, num_labels),\n",
    "                           nn.LogSoftmax(dim=1))\n",
    "\n",
    "# Replace default classifier with new classifier\n",
    "model.classifier = classifier\n",
    "\n",
    "# Find the device available to use using torch library\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "# Move model to the device specified above\n",
    "model.to(device)\n",
    "\n",
    "# Set the error function using torch.nn as nn library\n",
    "criterion = nn.NLLLoss()\n",
    "# Set the optimizer function using torch.optim as optim library\n",
    "optimizer = optim.Adam(model.classifier.parameters())\n",
    "\n",
    "# Training the Model\n",
    "epochs = 6\n",
    "start_train = time.time()\n",
    "epoch_array = []\n",
    "accu_array = []\n",
    "D00_TPR_array = []\n",
    "D00_FPR_array = []\n",
    "D01_TPR_array = []\n",
    "D01_FPR_array = []\n",
    "D10_TPR_array = []\n",
    "D10_FPR_array = []\n",
    "D11_TPR_array = []\n",
    "D11_FPR_array = []\n",
    "D20_TPR_array = []\n",
    "D20_FPR_array = []\n",
    "D40_TPR_array = []\n",
    "D40_FPR_array = []\n",
    "D43_TPR_array = []\n",
    "D43_FPR_array = []\n",
    "D44_TPR_array = []\n",
    "D44_FPR_array = []\n",
    "D00_TPR_array.append(0)\n",
    "D00_FPR_array.append(0)\n",
    "D01_TPR_array.append(0)\n",
    "D01_FPR_array.append(0)\n",
    "D10_TPR_array.append(0)\n",
    "D10_FPR_array.append(0)\n",
    "D11_TPR_array.append(0)\n",
    "D11_FPR_array.append(0)\n",
    "D20_TPR_array.append(0)\n",
    "D20_FPR_array.append(0)\n",
    "D40_TPR_array.append(0)\n",
    "D40_FPR_array.append(0)\n",
    "D43_TPR_array.append(0)\n",
    "D43_FPR_array.append(0)\n",
    "D44_TPR_array.append(0)\n",
    "D44_FPR_array.append(0)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    display_epoch = epoch + 1\n",
    "    print('Epoch:', display_epoch)\n",
    "    epoch_array.append(display_epoch)\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    accuracy = 0\n",
    "\n",
    "    # Training the model\n",
    "    model.train()\n",
    "    counter = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        # Move to device\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        # Clear optimizers\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        output = model.forward(inputs)\n",
    "        # Loss\n",
    "        loss = criterion(output, labels)\n",
    "        # Calculate gradients (backpropogation)\n",
    "        loss.backward()\n",
    "        # Adjust parameters based on gradients\n",
    "        optimizer.step()\n",
    "        # Add the loss to the training set's rnning loss\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        # Print the progress of our training\n",
    "        counter += 1\n",
    "        print(\"Batch:\", counter, \"out of\", len(train_loader))\n",
    "\n",
    "    end_train = time.time()\n",
    "    print('Finished Epoch', epoch + 1, 'Training in %0.2f minutes' % ((end_train - start_train) / 60))\n",
    "\n",
    "    # Evaluating the model\n",
    "    start_valid = time.time()\n",
    "    model.eval()\n",
    "    counter = 0\n",
    "\n",
    "    total_classes = 8\n",
    "    output = torch.randn(batch_size, total_classes)  # refer to output after softmax\n",
    "    target = torch.randint(0, total_classes, (batch_size,))  # labels\n",
    "    confusion_matrix = torch.zeros(total_classes, total_classes)\n",
    "\n",
    "    # Tell torch not to calculate gradients\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            # Move to device\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            # Forward pass\n",
    "            output = model.forward(inputs)\n",
    "            # Calculate Loss\n",
    "            valloss = criterion(output, labels)\n",
    "            # Add loss to the validation set's running loss\n",
    "            val_loss += valloss.item() * inputs.size(0)\n",
    "\n",
    "            # Since our model outputs a LogSoftmax, find the real\n",
    "            # percentages by reversing the log function\n",
    "            output = torch.exp(output)\n",
    "            # Get the top class of the output\n",
    "            top_p, top_class = output.topk(1, dim=1)\n",
    "            # See how many of the classes were correct?\n",
    "            equals = top_class == labels.view(*top_class.shape)\n",
    "            # Calculate the mean (get the accuracy for this batch)\n",
    "            # and add it to the running accuracy for this epoch\n",
    "            accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "            # Print the progress of our evaluation\n",
    "            counter += 1\n",
    "            print(\"Batch:\", counter, \"out of\", len(val_loader))\n",
    "\n",
    "            _, preds = torch.max(output, 1)\n",
    "\n",
    "            for p, t in zip(preds.view(-1), labels.view(-1)):\n",
    "                confusion_matrix[p.long(), t.long()] += 1\n",
    "\n",
    "        print(confusion_matrix)\n",
    "\n",
    "        TP = confusion_matrix.diag()\n",
    "\n",
    "        for c in range(total_classes):\n",
    "            idx = torch.ones(total_classes).byte()\n",
    "            idx[c] = 0\n",
    "            TN = confusion_matrix[idx.nonzero()[:, None], idx.nonzero()].sum()\n",
    "            FP = confusion_matrix[c, idx].sum()\n",
    "            FN = confusion_matrix[idx, c].sum()\n",
    "\n",
    "            sensitivity = (TP[c] / (TP[c] + FN))\n",
    "            specificity = (TN / (TN + FP))\n",
    "            FPR = 1 - specificity\n",
    "            # re_call = (TP[c] / (TP[c] + FP))\n",
    "            pre_cision = (TP[c] / (TP[c] + FN))\n",
    "            f1_score = 2 * ((pre_cision * sensitivity) / (pre_cision + sensitivity))\n",
    "            checking_c = c + 1\n",
    "            if (checking_c == 1):\n",
    "                D00_TPR_array.append(sensitivity)\n",
    "                D00_FPR_array.append(FPR)\n",
    "            elif (checking_c == 2):\n",
    "                D01_TPR_array.append(sensitivity)\n",
    "                D01_FPR_array.append(FPR)\n",
    "            elif (checking_c == 3):\n",
    "                D10_TPR_array.append(sensitivity)\n",
    "                D10_FPR_array.append(FPR)\n",
    "            elif (checking_c == 4):\n",
    "                D11_TPR_array.append(sensitivity)\n",
    "                D11_FPR_array.append(FPR)\n",
    "            elif (checking_c == 5):\n",
    "                D20_TPR_array.append(sensitivity)\n",
    "                D20_FPR_array.append(FPR)\n",
    "            elif (checking_c == 6):\n",
    "                D40_TPR_array.append(sensitivity)\n",
    "                D40_FPR_array.append(FPR)\n",
    "            elif (checking_c == 7):\n",
    "                D43_TPR_array.append(sensitivity)\n",
    "                D43_FPR_array.append(FPR)\n",
    "            else:\n",
    "                D44_TPR_array.append(sensitivity)\n",
    "                D44_FPR_array.append(FPR)\n",
    "\n",
    "            print('Class {}\\nTP {}, TN {}, FP {}, FN {}'.format(c + 1, TP[c], TN, FP, FN))\n",
    "            print('Sensitivity or Recall = {}'.format(sensitivity))\n",
    "            print('Specificity = {}'.format(specificity))\n",
    "            # print('Recall = {}'.format(re_call))\n",
    "            print('Precision = {}'.format(pre_cision))\n",
    "            print('F1 Score = {}'.format(f1_score))\n",
    "\n",
    "    end_valid = time.time()\n",
    "    print('Finished Epoch', epoch + 1, 'Validating in %0.2f minutes' % ((end_valid - start_valid) / 60))\n",
    "\n",
    "    # Get the average loss for the entire epoch\n",
    "    train_loss = train_loss / len(train_loader.dataset)\n",
    "    valid_loss = val_loss / len(val_loader.dataset)\n",
    "\n",
    "    record_accuracy = (accuracy / len(val_loader)) * 100\n",
    "    print(\"Record Accuracy\", record_accuracy, \" in epoch\", display_epoch)\n",
    "    accu_array.append(record_accuracy)\n",
    "\n",
    "    # Print out the information\n",
    "    print('Accuracy: %0.3f %%' % (accuracy / len(val_loader) * 100))\n",
    "    print('Training Loss: {:.6f} ' '\\tValidation Loss: {:.6f}'.format(train_loss, valid_loss), '\\n')\n",
    "\n",
    "    print('Total Time is %0.2f minutes' % ((end_valid - start_train) / 60))\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Create model directory\n",
    "model_dir = Path(\"saved_model\")\n",
    "model_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# 1. Save full model (architecture + weights)\n",
    "torch.save(model, model_dir/'road_damage_model.pth')\n",
    "\n",
    "# 2. Save state dict (recommended for production)\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'class_to_idx': train_set.class_to_idx,\n",
    "}, model_dir/'model_state.pth')\n",
    "\n",
    "# 3. Save class labels\n",
    "with open(model_dir/'class_labels.json', 'w') as f:\n",
    "    json.dump(train_set.classes, f)\n",
    "\n",
    "# 4. Save transformation parameters\n",
    "transform_config = {\n",
    "    'resize': 255,\n",
    "    'crop': 224,\n",
    "    'mean': [0.485, 0.456, 0.406],\n",
    "    'std': [0.229, 0.224, 0.225]\n",
    "}\n",
    "with open(model_dir/'transform_config.json', 'w') as f:\n",
    "    json.dump(transform_config, f)\n",
    "\n",
    "# 5. Save model architecture details\n",
    "model_architecture = {\n",
    "    'base_model': 'densenet161',\n",
    "    'classifier': {\n",
    "        'input_features': classifier_input,\n",
    "        'layers': [64, 32, num_labels],\n",
    "        'activation': 'ReLU',\n",
    "        'output_activation': 'LogSoftmax'\n",
    "    }\n",
    "}\n",
    "with open(model_dir/'model_architecture.json', 'w') as f:\n",
    "    json.dump(model_architecture, f)\n",
    "\n",
    "\n",
    "print(f\"\\nModel and assets saved in {model_dir} directory\")\n",
    "D00_TPR_array.append(1)\n",
    "D00_FPR_array.append(1)\n",
    "D01_TPR_array.append(1)\n",
    "D01_FPR_array.append(1)\n",
    "D10_TPR_array.append(1)\n",
    "D10_FPR_array.append(1)\n",
    "D11_TPR_array.append(1)\n",
    "D11_FPR_array.append(1)\n",
    "D20_TPR_array.append(1)\n",
    "D20_FPR_array.append(1)\n",
    "D40_TPR_array.append(1)\n",
    "D40_FPR_array.append(1)\n",
    "D43_TPR_array.append(1)\n",
    "D43_FPR_array.append(1)\n",
    "D44_TPR_array.append(1)\n",
    "D44_FPR_array.append(1)\n",
    "\n",
    "D00_TPR_array.sort()\n",
    "D00_FPR_array.sort()\n",
    "D01_TPR_array.sort()\n",
    "D01_FPR_array.sort()\n",
    "D10_TPR_array.sort()\n",
    "D10_FPR_array.sort()\n",
    "D11_TPR_array.sort()\n",
    "D11_FPR_array.sort()\n",
    "D20_TPR_array.sort()\n",
    "D20_FPR_array.sort()\n",
    "D40_TPR_array.sort()\n",
    "D40_FPR_array.sort()\n",
    "D43_TPR_array.sort()\n",
    "D43_FPR_array.sort()\n",
    "D44_TPR_array.sort()\n",
    "D44_FPR_array.sort()\n",
    "\n",
    "# Title\n",
    "plt.title('ROC Plot for DenseNet161')\n",
    "# Axis labels\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.plot(D00_FPR_array, D00_TPR_array, color='blue', linewidth=3, label='D00')\n",
    "plt.plot(D01_FPR_array, D01_TPR_array, color='green', linewidth=3, label='D01')\n",
    "plt.plot(D10_FPR_array, D10_TPR_array, color='orange', linewidth=3, label='D10')\n",
    "plt.plot(D11_FPR_array, D11_TPR_array, color='black', linewidth=3, label='D11')\n",
    "plt.plot(D20_FPR_array, D20_TPR_array, color='cyan', linewidth=3, label='D20')\n",
    "plt.plot(D40_FPR_array, D40_TPR_array, color='lavender', linewidth=3, label='D40')\n",
    "plt.plot(D43_FPR_array, D43_TPR_array, color='lime', linewidth=3, label='D43')\n",
    "plt.plot(D44_FPR_array, D44_TPR_array, color='coral', linewidth=3, label='D44')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Title\n",
    "plt.title('Epoch Vs Accuracy for DenseNet161')\n",
    "# Axis labels\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(epoch_array, accu_array)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model and assets saved in saved_model directory\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Create model directory\n",
    "model_dir = Path(\"saved_model\")\n",
    "model_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# 1. Save full model (architecture + weights)\n",
    "torch.save(model, model_dir/'road_damage_model.pth')\n",
    "\n",
    "# 2. Save state dict (recommended for production)\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'class_to_idx': train_set.class_to_idx,\n",
    "}, model_dir/'model_state.pth')\n",
    "\n",
    "# 3. Save class labels\n",
    "with open(model_dir/'class_labels.json', 'w') as f:\n",
    "    json.dump(train_set.classes, f)\n",
    "\n",
    "# 4. Save transformation parameters\n",
    "transform_config = {\n",
    "    'resize': 255,\n",
    "    'crop': 224,\n",
    "    'mean': [0.485, 0.456, 0.406],\n",
    "    'std': [0.229, 0.224, 0.225]\n",
    "}\n",
    "with open(model_dir/'transform_config.json', 'w') as f:\n",
    "    json.dump(transform_config, f)\n",
    "\n",
    "# 5. Save model architecture details\n",
    "model_architecture = {\n",
    "    'base_model': 'densenet161',\n",
    "    'classifier': {\n",
    "        'input_features': classifier_input,\n",
    "        'layers': [64, 32, num_labels],\n",
    "        'activation': 'ReLU',\n",
    "        'output_activation': 'LogSoftmax'\n",
    "    }\n",
    "}\n",
    "with open(model_dir/'model_architecture.json', 'w') as f:\n",
    "    json.dump(model_architecture, f)\n",
    "\n",
    "print(f\"\\nModel and assets saved in {model_dir} directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantize the model\n",
    "quantized_model = quantize_dynamic(model, {nn.Linear}, dtype=torch.qint8)\n",
    "\n",
    "# Save quantized model (expected size < 100MB)\n",
    "torch.save(quantized_model.state_dict(), \"saved_model/quantized_model.pth\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "DenseNet161_Image_Classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "408ba5c24fe84cba91ebb5dd2646e209": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "508be4b681de4f919edca4f319439a0e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "58f1887301894637a3ac898a12e3c8bd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "83e2a80ebc624b76a138fa715a3bc60a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9fd4845738054238b62e6f264e9b2f44",
      "placeholder": "",
      "style": "IPY_MODEL_408ba5c24fe84cba91ebb5dd2646e209",
      "value": " 110M/110M [00:06&lt;00:00, 17.9MB/s]"
     }
    },
    "9fd4845738054238b62e6f264e9b2f44": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c8303ba8d6724474b954ff977d7fd20d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_508be4b681de4f919edca4f319439a0e",
      "max": 115730790,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_dfbebb0075d64540963015a7f02f4645",
      "value": 115730790
     }
    },
    "df59349a91be49958f0e9c952eab70e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c8303ba8d6724474b954ff977d7fd20d",
       "IPY_MODEL_83e2a80ebc624b76a138fa715a3bc60a"
      ],
      "layout": "IPY_MODEL_58f1887301894637a3ac898a12e3c8bd"
     }
    },
    "dfbebb0075d64540963015a7f02f4645": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
